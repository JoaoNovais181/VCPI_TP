{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchinfo\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import vcpi_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_III(model, train_loader, val_loader, epochs, loss_fn, optimizer, scheduler, early_stopper, transform: transforms.Compose, save_prefix = 'model'):\n",
    "\n",
    "    history = {}\n",
    "    history['accuracy'] = []\n",
    "    history['val_acc'] = []\n",
    "    history['val_loss'] = []\n",
    "    history['loss'] = []\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        model.train()\n",
    "        start_time = time.time() \n",
    "        correct = 0\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, targets) in enumerate(train_loader, 0):\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "            correct += (predicted == targets).sum()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            v_correct = 0\n",
    "            val_loss = 0.0\n",
    "            for i,t in val_loader:\n",
    "                \n",
    "                transform(i)\n",
    "                i = i.to(device)\n",
    "                t = t.to(device)\n",
    "                o = model(i)\n",
    "                _,p = torch.max(o,1)\n",
    "                \n",
    "                #with torch.no_grad():\n",
    "                val_loss += loss_fn(o, t)\n",
    "\n",
    "                v_correct += (p == t).sum()\n",
    "\n",
    "        old_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(val_loss)\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        if old_lr != new_lr:\n",
    "            print('==> Learning rate updated: ', old_lr, ' -> ', new_lr)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        accuracy = 100 * correct / len(train_loader.dataset)\n",
    "        v_accuracy = 100 * v_correct / len(val_loader.dataset)\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        stop_time = time.time()\n",
    "        print(f'Epoch: {epoch:03d}; Loss: {epoch_loss:0.6f}; Accuracy: {accuracy:0.4f}; Val Loss: {val_loss:0.6f}; Val Acc: {v_accuracy:0.4f}; Elapsed time: {(stop_time - start_time):0.4f}')\n",
    "        history['accuracy'].append(accuracy.cpu().numpy())\n",
    "        history['val_acc'].append(v_accuracy.cpu().numpy())\n",
    "        history['val_loss'].append(val_loss.cpu().detach().numpy())\n",
    "        history['loss'].append(epoch_loss.cpu().detach().numpy())\n",
    " \n",
    "        ###### Saving ######\n",
    "        if val_loss < best_val_loss:\n",
    "           \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model':model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict()\n",
    "                },\n",
    "                f'{save_prefix}_best.pt')\n",
    "\n",
    "        if early_stopper(val_loss):\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "        \n",
    "    print('Finished Training')\n",
    "\n",
    "    return(history)\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "\n",
    "    # sets the model in evaluation mode.\n",
    "    # although our model does not have layers which behave differently during training and evaluation\n",
    "    # this is a good practice as the models architecture may change in the future\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    \n",
    "    for i, (images, targets) in enumerate(data_loader):\n",
    "         \n",
    "        # forward pass, compute the output of the model for the current batch\n",
    "        outputs = model(images.to(device))\n",
    "\n",
    "        # \"max\" returns a namedtuple (values, indices) where values is the maximum \n",
    "        # value of each row of the input tensor in the given dimension dim; \n",
    "        # indices is the index location of each maximum value found (argmax).\n",
    "        # the argmax effectively provides the predicted class number        \n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "        correct += (preds.cpu() == targets).sum()\n",
    "\n",
    "    return (correct / len(data_loader.dataset)).item()\n",
    "\n",
    "\n",
    "class Conv(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, 3)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(16)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, 3)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(32)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(2)\n",
    "\n",
    "\n",
    "        self.conv3 = torch.nn.Conv2d(32, 48, 3)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(48)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "\n",
    "        self.conv4 = torch.nn.Conv2d(48, 48, 3)\n",
    "        self.bn4 = torch.nn.BatchNorm2d(48)\n",
    "        self.relu4 = torch.nn.ReLU()\n",
    "\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(2)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(1200, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):    \n",
    "        \n",
    "        # input = (bs, 3, 32, 32)\n",
    "        x = self.conv1(x) # -> (bs, 16, 30, 30)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x) # -> (bs, 32, 28, 28)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool1(x) # -> (bs, 32, 14, 14)\n",
    "        \n",
    "        x = self.conv3(x) # -> (bs, 48, 12, 12)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x) # -> (bs, 48, 10, 10)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.maxpool2(x) # -> (bs, 48, 5, 5)\n",
    "        \n",
    "        x = torch.flatten(x,1) # -> (bs, 48 * 5 * 5 = 1200)\n",
    "        x = self.fc1(x)        # -> (bs, num_classes)\n",
    "\n",
    "        return(x)\n",
    "\n",
    "\n",
    "\n",
    "class Early_Stopping():\n",
    "\n",
    "    def __init__(self, patience = 3, min_delta = 0.00001):\n",
    "\n",
    "        self.patience = patience \n",
    "        self.min_delta = min_delta\n",
    "\n",
    "        self.min_delta\n",
    "        self.min_val_loss = float('inf')\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "\n",
    "        # improvement\n",
    "        if val_loss + self.min_delta < self.min_val_loss:\n",
    "            self.min_val_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "        # no improvement            \n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter > self.patience:\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "def build_confusion_matrix(model, dataset):\n",
    "\n",
    "    preds = []\n",
    "    ground_truth = []\n",
    "\n",
    "    for images, targets in dataset:\n",
    "\n",
    "        predictions = model(images.to(device))\n",
    "        preds_sparse = [np.argmax(x) for x in predictions.cpu().detach().numpy()]\n",
    "        preds.extend(preds_sparse)\n",
    "        ground_truth.extend(targets.numpy())\n",
    "\n",
    "    vcpi_util.show_confusion_matrix(ground_truth, preds, len(test_set.classes))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "PATH_TRAINING_SET = 'dataset/train'\n",
    "PATH_TEST_SET = 'dataset/test'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "EPOCHS = 30\n",
    "img_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.RandomRotation(50),\n",
    "    v2.Resize((img_size, img_size)), \n",
    "    v2.RandomErasing(0.5, (0.1,0.1)),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "\n",
    "transformNormal = transforms.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((img_size, img_size)), \n",
    "    v2.ToDtype(torch.float32)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set: torchvision.datasets.ImageFolder = torchvision.datasets.ImageFolder(root=PATH_TRAINING_SET, transform = transformNormal)\n",
    "\n",
    "train_sub_set, val_sub_set = torch.utils.data.random_split(train_set, [0.8, 0.2])\n",
    "\n",
    "train_loader: torch.utils.data.DataLoader = torch.utils.data.DataLoader(train_sub_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader: torch.utils.data.DataLoader = torch.utils.data.DataLoader(val_sub_set, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_set: torchvision.datasets.ImageFolder = torchvision.datasets.ImageFolder(root=PATH_TEST_SET, transform = transformNormal)\n",
    "test_loader: torch.utils.data.DataLoader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (conv4): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu4): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1200, out_features=43, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Conv                                     [32, 43]                  --\n",
       "├─Conv2d: 1-1                            [32, 16, 30, 30]          448\n",
       "├─BatchNorm2d: 1-2                       [32, 16, 30, 30]          32\n",
       "├─ReLU: 1-3                              [32, 16, 30, 30]          --\n",
       "├─Conv2d: 1-4                            [32, 32, 28, 28]          4,640\n",
       "├─BatchNorm2d: 1-5                       [32, 32, 28, 28]          64\n",
       "├─ReLU: 1-6                              [32, 32, 28, 28]          --\n",
       "├─MaxPool2d: 1-7                         [32, 32, 14, 14]          --\n",
       "├─Conv2d: 1-8                            [32, 48, 12, 12]          13,872\n",
       "├─BatchNorm2d: 1-9                       [32, 48, 12, 12]          96\n",
       "├─ReLU: 1-10                             [32, 48, 12, 12]          --\n",
       "├─Conv2d: 1-11                           [32, 48, 10, 10]          20,784\n",
       "├─BatchNorm2d: 1-12                      [32, 48, 10, 10]          96\n",
       "├─ReLU: 1-13                             [32, 48, 10, 10]          --\n",
       "├─MaxPool2d: 1-14                        [32, 48, 5, 5]            --\n",
       "├─Linear: 1-15                           [32, 43]                  51,643\n",
       "==========================================================================================\n",
       "Total params: 91,675\n",
       "Trainable params: 91,675\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 261.40\n",
       "==========================================================================================\n",
       "Input size (MB): 0.39\n",
       "Forward/backward pass size (MB): 26.23\n",
       "Params size (MB): 0.37\n",
       "Estimated Total Size (MB): 26.99\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Conv(len(train_set.classes))\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "torchinfo.summary(model, input_size=(BATCH_SIZE, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor = 0.1, patience=3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "early_stop = Early_Stopping(9)\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((img_size, img_size)), \n",
    "    v2.ColorJitter(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Learning rate updated:  0.0001  ->  1e-05\n",
      "Epoch: 000; Loss: 0.001340; Accuracy: 98.6037; Val Loss: 0.001515; Val Acc: 98.4441; Elapsed time: 67.2687\n",
      "Epoch: 001; Loss: 0.001185; Accuracy: 98.7822; Val Loss: 0.001508; Val Acc: 98.3038; Elapsed time: 64.5375\n",
      "Epoch: 002; Loss: 0.001242; Accuracy: 98.6228; Val Loss: 0.001629; Val Acc: 98.3931; Elapsed time: 65.4838\n",
      "Epoch: 003; Loss: 0.001109; Accuracy: 98.7503; Val Loss: 0.001532; Val Acc: 98.5334; Elapsed time: 66.5447\n",
      "Epoch: 004; Loss: 0.001162; Accuracy: 98.7408; Val Loss: 0.001455; Val Acc: 98.5334; Elapsed time: 67.0167\n",
      "Epoch: 005; Loss: 0.001182; Accuracy: 98.7790; Val Loss: 0.001472; Val Acc: 98.4186; Elapsed time: 66.7524\n",
      "Epoch: 006; Loss: 0.001222; Accuracy: 98.7344; Val Loss: 0.001749; Val Acc: 98.2528; Elapsed time: 67.7951\n",
      "Epoch: 007; Loss: 0.001172; Accuracy: 98.7471; Val Loss: 0.001507; Val Acc: 98.3548; Elapsed time: 67.3014\n",
      "Epoch: 008; Loss: 0.001183; Accuracy: 98.7950; Val Loss: 0.001400; Val Acc: 98.5844; Elapsed time: 68.4479\n",
      "Epoch: 009; Loss: 0.001160; Accuracy: 98.7439; Val Loss: 0.001337; Val Acc: 98.5206; Elapsed time: 68.7113\n",
      "Epoch: 010; Loss: 0.001229; Accuracy: 98.6738; Val Loss: 0.001442; Val Acc: 98.6099; Elapsed time: 68.0791\n",
      "Epoch: 011; Loss: 0.001226; Accuracy: 98.7312; Val Loss: 0.001509; Val Acc: 98.5206; Elapsed time: 66.7791\n",
      "Epoch: 012; Loss: 0.001177; Accuracy: 98.7408; Val Loss: 0.001348; Val Acc: 98.6226; Elapsed time: 68.3041\n",
      "==> Learning rate updated:  1e-05  ->  1.0000000000000002e-06\n",
      "Epoch: 013; Loss: 0.001169; Accuracy: 98.7503; Val Loss: 0.001583; Val Acc: 98.3421; Elapsed time: 67.7137\n",
      "Epoch: 014; Loss: 0.001130; Accuracy: 98.8205; Val Loss: 0.001415; Val Acc: 98.5971; Elapsed time: 67.8699\n",
      "Epoch: 015; Loss: 0.001128; Accuracy: 98.7950; Val Loss: 0.001482; Val Acc: 98.4696; Elapsed time: 68.8434\n",
      "Epoch: 016; Loss: 0.001106; Accuracy: 98.7694; Val Loss: 0.001562; Val Acc: 98.2910; Elapsed time: 68.3016\n",
      "==> Learning rate updated:  1.0000000000000002e-06  ->  1.0000000000000002e-07\n",
      "Epoch: 017; Loss: 0.001135; Accuracy: 98.7312; Val Loss: 0.001424; Val Acc: 98.4568; Elapsed time: 69.0661\n",
      "Epoch: 018; Loss: 0.001145; Accuracy: 98.7631; Val Loss: 0.001567; Val Acc: 98.4696; Elapsed time: 67.9587\n",
      "Epoch: 019; Loss: 0.001230; Accuracy: 98.7280; Val Loss: 0.001513; Val Acc: 98.5589; Elapsed time: 68.6045\n",
      "Early stopping!\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "history = train_III(model, train_loader, val_loader, EPOCHS, loss_fn, optimizer, scheduler, early_stop, 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VCPI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
